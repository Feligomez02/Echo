/**
 * Script para ejecutar ambos scrapers (La Estaci√≥n y La F√°brica)
 * y guardar los eventos en Supabase (local y production)
 */

// Load environment variables from .env and .env.local
import * as dotenv from 'dotenv';
dotenv.config({ path: '.env' });
dotenv.config({ path: '.env.local' });

import { scrapeEstacion } from '../services/scraper-estacion';
import { scrapeFabrica } from '../services/scraper-fabrica';

async function saveShowsToSupabase(shows: any[], venue: string) {
  console.log(`\nüì§ Sending ${shows.length} shows from ${venue} to Supabase...`);
  
  try {
    // Use production URL by default for scraper uploads
    const apiUrl = 'https://echo-e8dt.vercel.app';
    const scraperKey = 'Qoh09wVDWFqChfghw6CF2cfLjv6XrOIVhcqpBuaaxHg=';

    const response = await fetch(`${apiUrl}/api/admin/scrape/save`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${scraperKey}`,
      },
      body: JSON.stringify({ shows, venue }),
    });

    if (!response.ok) {
      const error = await response.text();
      console.error(`‚ùå Error from API (${response.status}):`, error);
      return { created: 0, updated: 0, skipped: 0 };
    }

    const result = await response.json();
    console.log(`‚úÖ API Response: ${result.stats.created} created, ${result.stats.updated} updated, ${result.stats.skipped} skipped`);
    
    if (result.errors && result.errors.length > 0) {
      console.warn('‚ö†Ô∏è Some errors occurred:');
      result.errors.slice(0, 3).forEach((err: string) => console.warn(`  - ${err}`));
    }

    return result.stats;
  } catch (error) {
    console.error('‚ùå Failed to save shows:', error);
    return { created: 0, updated: 0, skipped: 0 };
  }
}

async function main() {
  try {
    console.log('üé≠ INICIANDO SCRAPING DE EVENTOS\n');
    console.log('‚ïê'.repeat(60));

    // Scrape La Estaci√≥n
    console.log('\n1Ô∏è‚É£  Scrapeando La Estaci√≥n...\n');
    let estacionShows = await scrapeEstacion();
    console.log(`‚úÖ Extra√≠dos ${estacionShows.length} shows de La Estaci√≥n`);

    let estacionStats = await saveShowsToSupabase(estacionShows, 'La Estaci√≥n');

    // Scrape La F√°brica
    console.log('\n2Ô∏è‚É£  Scrapeando La F√°brica...\n');
    let fabricaShows = await scrapeFabrica();
    console.log(`‚úÖ Extra√≠dos ${fabricaShows.length} shows de La F√°brica`);

    let fabricaStats = await saveShowsToSupabase(fabricaShows, 'La F√°brica');

    // Resumen final
    console.log('\n' + '‚ïê'.repeat(60));
    console.log('üìä RESUMEN FINAL DEL SCRAPING\n');
    console.log(`La Estaci√≥n: ${estacionStats.created} nuevos, ${estacionStats.updated} actualizados, ${estacionStats.skipped} omitidos`);
    console.log(`La F√°brica:  ${fabricaStats.created} nuevos, ${fabricaStats.updated} actualizados, ${fabricaStats.skipped} omitidos`);
    console.log(`\n‚ú® Total nuevo: ${estacionStats.created + fabricaStats.created} eventos`);
    console.log(`üîÑ Total actualizado: ${estacionStats.updated + fabricaStats.updated} eventos`);
    console.log('‚ïê'.repeat(60) + '\n');

  } catch (error) {
    console.error('‚ùå Error en el scraping:', error);
    process.exit(1);
  }
}

main();

